import os
import fitz
import easyocr
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from pathlib import Path
from typing import List
from langchain.schema import Document
from langchain_teddynote.document_loaders import HWPLoader
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers.util import cos_sim
from src.utils.path import get_project_root_dir

# EasyOCR Reader ê°ì²´ ìƒì„± (GPU ì‚¬ìš©)
# í•œê¸€(ko) + ì˜ì–´(en)ë¥¼ ì¸ì‹í•˜ë©°, ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œë¨
reader = easyocr.Reader(['ko', 'en'], gpu=True)


def safe_ocr(img_array: np.ndarray, ocr_reader: easyocr.Reader) -> str:
    """
    ì´ë¯¸ì§€ ë°°ì—´ì„ ì…ë ¥ë°›ì•„ EasyOCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        img_array (np.ndarray): OCRì„ ìˆ˜í–‰í•  ì´ë¯¸ì§€ ë°°ì—´
        ocr_reader (easyocr.Reader): ì´ˆê¸°í™”ëœ EasyOCR ë¦¬ë” ì¸ìŠ¤í„´ìŠ¤

    Returns:
        str: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    try:
        result = ocr_reader.readtext(img_array, detail=0)
        if not isinstance(result, list):
            return ""
        return "\n".join(result)
    except Exception as e:
        raise RuntimeError(f"âŒ [OCR] (data_loader.safe_ocr) OCR ì²˜ë¦¬ ì‹¤íŒ¨: {e}")


def extract_text_from_pdf(pdf_path: Path, apply_ocr: bool = True) -> str:
    """
    PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë° OCR í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        pdf_path (Path): ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ
        apply_ocr (bool): OCR ìˆ˜í–‰ ì—¬ë¶€

    Returns:
        str: ì „ì²´ í˜ì´ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    if not pdf_path.exists():
        raise FileNotFoundError(f"âŒ(data_loader.extract_text_from_pdf.pdf_path) PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
    
    full_text = ""
    try:
        with fitz.open(pdf_path) as doc:
            for page_num, page in enumerate(tqdm(doc, desc=f"{pdf_path.name}")):
                try:
                    page_text = page.get_text()
                    full_text += page_text

                    if apply_ocr:
                        pix = page.get_pixmap(dpi=300)
                        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                        ocr_text = safe_ocr(np.array(img), reader)
                        if ocr_text.strip():
                            full_text += f"\n[OCR p.{page_num + 1}]\n{ocr_text}"
                except Exception as e:
                    print(f"âš ï¸ [Warning] (data_loader.extract_text_from_pdf) í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    except Exception as e:
        raise RuntimeError(f"âŒ [Runtime] (data_loader.extract_text_from_pdf) PDF íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    return full_text


def retrieve_top_documents_from_metadata(query, csv_path, embed_model, top_k=5, verbose=False):
    """
    ì‚¬ìš©ì ì§ˆë¬¸(query)ê³¼ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°(csv)ì— ê¸°ë°˜í•˜ì—¬ 
    ê°€ì¥ ìœ ì‚¬í•œ top_kê°œì˜ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Parameters:
        query (str): ì‚¬ìš©ì ì§ˆë¬¸
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ
        embed_model (str): ì„ë² ë”© ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "openai", "huggingface")
        top_k (int): ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’ 5)
        verbose (bool): ê²°ê³¼ë¥¼ í‘œ í˜•íƒœë¡œ ì¶œë ¥í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’ False)

    Returns:
        pd.DataFrame: ìƒìœ„ top_k ë¬¸ì„œ ì •ë³´ + ìœ ì‚¬ë„ ì ìˆ˜
    """
    try:  # ìˆ˜ì •ë¶€ë¶„: ì „ì²´ í•¨ìˆ˜ ë°©ì–´ì  ì²˜ë¦¬ ì‹œì‘
        from src.embedding.vector_db import generate_embedding
        embedder = generate_embedding(embed_model)
        if embedder is not None:
            if verbose:
                print(f"    ğŸ“Œ [Info] Embedding model: {embedder.__class__.__name__}")

        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"âŒ (loader.data_loader.retrieve_top_documents_from_metadata) íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

        try:
            df = pd.read_csv(csv_path)
        except Exception as e:
            raise ValueError(f"âŒ (loader.data_loader.retrieve_top_documents_from_metadata) CSV íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {str(e)}")

        required_columns = ["ì‚¬ì—…ëª…", "ë°œì£¼ ê¸°ê´€", "ì‚¬ì—… ìš”ì•½", "íŒŒì¼ëª…"]
        for col in required_columns:
            if col not in df.columns:
                raise KeyError(f"âŒ (loader.data_loader.retrieve_top_documents_from_metadata) '{col}' ì—´ì´ CSVì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        def make_embedding_text(row):
            return f"{row['ì‚¬ì—…ëª…']} {row['ë°œì£¼ ê¸°ê´€']} {row['ì‚¬ì—… ìš”ì•½']}"

        try:
            df["ì„ë² ë”©í…ìŠ¤íŠ¸"] = df.apply(make_embedding_text, axis=1)
        except Exception as e:
            raise RuntimeError(f"âŒ (loader.data_loader.retrieve_top_documents_from_metadata) ì„ë² ë”© í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

        doc_texts = df["ì„ë² ë”©í…ìŠ¤íŠ¸"].tolist()

        if hasattr(embedder, "encode"):
            doc_embeddings = embedder.encode(doc_texts, convert_to_tensor=True)
            query_embedding = embedder.encode(query, convert_to_tensor=True)
            similarities = cos_sim(query_embedding, doc_embeddings)[0].cpu().numpy()
        else:
            doc_embeddings = embedder.embed_documents(doc_texts)
            query_embedding = embedder.embed_query(query)
            similarities = cosine_similarity(
                np.array([query_embedding]), np.array(doc_embeddings)
            )[0]

        top_k_indices = np.argsort(similarities)[::-1][:top_k]

        try:
            top_docs = df.iloc[top_k_indices].copy()
            top_docs["ìœ ì‚¬ë„"] = similarities[top_k_indices]
        except Exception as e:
            raise RuntimeError(f"âŒ (loader.data_loader.retrieve_top_documents_from_metadata) ê²°ê³¼ DataFrame ìƒì„± ì‹¤íŒ¨: {str(e)}")

        if verbose == True:
            from tabulate import tabulate
            table = [
                [idx, row["íŒŒì¼ëª…"], f"{row['ìœ ì‚¬ë„']:.4f}"]
                for idx, row in top_docs.iterrows()
            ]
            output = tabulate(table, headers=["IDX", "íŒŒì¼ëª…", "ìœ ì‚¬ë„"], tablefmt="github")
            print("\n".join("    " + line for line in output.splitlines()))  # ìˆ˜ì •ë¶€ë¶„: 4ì¹¸ ë“¤ì—¬ì“°ê¸° ì ìš©

        return top_docs
    except Exception as e:
        raise RuntimeError(f"âŒ (loader.data_loader.retrieve_top_documents_from_metadata) ì˜ˆì™¸ ë°œìƒ: {e}")  # ìˆ˜ì •ë¶€ë¶„: ì „ì²´ í•¨ìˆ˜ ë°©ì–´ì  ì²˜ë¦¬ ë

from src.utils.path import get_project_root_dir

def data_process(df: pd.DataFrame, apply_ocr: bool = True, file_type: str = "all") -> pd.DataFrame:
    """
    HWP ë˜ëŠ” PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  full_text ì»¬ëŸ¼ì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        df (pd.DataFrame): íŒŒì¼ ëª©ë¡ì„ í¬í•¨í•œ ë°ì´í„°í”„ë ˆì„
        apply_ocr (bool): PDF OCR ì—¬ë¶€
        file_type (str): 'hwp', 'pdf', 'all' ì¤‘ í•˜ë‚˜

    Returns:
        pd.DataFrame: í…ìŠ¤íŠ¸ê°€ ì¶”ê°€ëœ DataFrame
    """
    base_dir = get_project_root_dir()
    file_root = os.path.join(base_dir, "data", "files")

    if file_type in ["hwp", "pdf"]:
        mask = df['íŒŒì¼ëª…'].str.lower().str.endswith(f".{file_type}")
        filtered_df = df[mask].copy()
    elif file_type == "all":
        filtered_df = df.copy()

    filtered_df['full_text'] = None

    for file_name in filtered_df['íŒŒì¼ëª…']:
        file_path = os.path.join(file_root, file_name)
        try:
            if not os.path.exists(file_path):
                 raise FileNotFoundError(f"âŒ [FileNotFound] (data_loader.data_process.path) íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

            if file_name.lower().endswith(".hwp") and file_type in ["hwp", "all"]:
                loader = HWPLoader(file_path)
                docs = loader.load()
                if docs and isinstance(docs[0].page_content, str):
                    filtered_df.loc[filtered_df['íŒŒì¼ëª…'] == file_name, 'full_text'] = docs[0].page_content
                else:
                    print(f"âš ï¸ [Warning] (data_loader.data_process.hwp) HWP íŒŒì¼ ë¬´ì‹œë¨ (ë‚´ìš© ì—†ìŒ): {file_name}")

            elif file_name.lower().endswith(".pdf") and file_type in ["pdf", "all"]:
                text = extract_text_from_pdf(Path(file_path), apply_ocr=apply_ocr)
                filtered_df.loc[filtered_df['íŒŒì¼ëª…'] == file_name, 'full_text'] = text

            else:
                print(f"âš ï¸ [Warning] (data_loader.data_process) ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_name}")

        except Exception as e:
            raise RuntimeError(f"âŒ [Runtime] (data_loader.data_process) íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file_name}): {e}")  

    return filtered_df.reset_index(drop=True)
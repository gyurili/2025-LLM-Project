import os
from typing import List, Union, Optional, Literal

import faiss
from dotenv import load_dotenv
from tqdm import tqdm

from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_chroma import Chroma
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.vectorstores.base import VectorStore

from src.utils.path import get_project_root_dir


def generate_embedding(embed_model_name: str) -> Union[OpenAIEmbeddings, HuggingFaceEmbeddings]:
    """
    ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        embed_model_name (str): 'openai' ë˜ëŠ” huggingface ëª¨ë¸ ì´ë¦„

    Returns:
        ì„ë² ë”© ê°ì²´

    Raises:
        ValueError: ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
    """
    try:
        if embed_model_name == "openai":
            load_dotenv()
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return OpenAIEmbeddings(model="text-embedding-3-large", openai_api_key=api_key)
        else:
            return HuggingFaceEmbeddings(model_name=embed_model_name)
    except Exception as e:
        raise ValueError(f"âŒ [Value] (vector_db.generate_embedding) ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


def generate_vector_db(
    all_chunks: List[Document],
    embed_model_name: str,
    index_name: str,
    db_type: str = "faiss",
    is_save: bool = True,
    batch_size: int = 128
) -> Union[FAISS, Chroma]:
    """
    FAISS ë˜ëŠ” Chroma ê¸°ë°˜ ë²¡í„° DBë¥¼ ìƒì„±í•˜ê³  ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not all_chunks or not isinstance(all_chunks, list):
        raise ValueError("âŒ [Value] (vector_db.generate_vector_db) all_chunksëŠ” ë¹„ì–´ ìˆì§€ ì•Šì€ Document ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    embeddings = generate_embedding(embed_model_name)
    print(f"ğŸ“Œ [Info] Embedding model: {embeddings.__class__.__name__}")

    try:
        if isinstance(embeddings, (HuggingFaceEmbeddings, OpenAIEmbeddings)):
            dimension = len(embeddings.embed_query("hello world"))
        else:
            dimension = 1536  # default
    except Exception as e:
        raise ValueError(f"âŒ [Value] (vector_db.generate_vector_db) ì„ë² ë”© ì°¨ì› ê³„ì‚° ì‹¤íŒ¨: {e}")

    try:
        output_path = os.path.join(get_project_root_dir(), "data")
        os.makedirs(output_path, exist_ok=True)

        if db_type == "faiss":
            print(f"ğŸ“Œ [info] Vector DB type: {db_type}")
            vector_store = FAISS(
                embedding_function=embeddings,
                index=faiss.IndexFlatL2(dimension),
                docstore=InMemoryDocstore(),
                index_to_docstore_id={},
            )
            vector_store = add_docs_in_batch(vector_store, all_chunks)
            if is_save:
                vector_store.save_local(folder_path=output_path, index_name=index_name)
                print("âœ… [Success] FAISS vector DB ì €ì¥ ì„±ê³µ.")

        elif db_type == "chroma":
            print(f"ğŸ“Œ [info] Vector DB type: {db_type}")
            chroma_path = os.path.join(output_path, index_name)
            if os.path.exists(chroma_path):
                import shutil
                shutil.rmtree(chroma_path)
                print(f"âš ï¸ [Notification] {db_type} ë®ì–´ì“°ê¸° ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ì´ì „ ìƒì„± DB ì œê±°...")

            vector_store = Chroma(
                embedding_function=embeddings,
                persist_directory=chroma_path,
                collection_name="chroma_db",
            )
            vector_store = add_docs_in_batch(vector_store, all_chunks)
            print("âœ… [Success] Chroma vector DB ì €ì¥ ì„±ê³µ.")

        else:
            raise ValueError("âŒ [Value] (vector_db.generate_vector_db) ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²¡í„° DB íƒ€ì…ì…ë‹ˆë‹¤. ('faiss' ë˜ëŠ” 'chroma' ì‚¬ìš©)")

        return vector_store

    except Exception as e:
        raise RuntimeError(f"âŒ [Runtime] (vector_db.generate_vector_db) ë²¡í„° DB ìƒì„± ì‹¤íŒ¨: {e}")


def load_vector_db(
    path: str,
    embed_model_name: str,
    index_name: str,
    db_type: str = "faiss"
) -> Union[FAISS, Chroma]:
    """
    ë¡œì»¬ì—ì„œ ì €ì¥ëœ FAISS ë˜ëŠ” Chroma ë²¡í„° DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ [FileNotFound] (vector_db.load_vector_db.path) ë²¡í„° DB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")

    try:
        embeddings = generate_embedding(embed_model_name)

        if db_type == "faiss":
            return FAISS.load_local(
                folder_path=path,
                index_name=index_name,
                embeddings=embeddings,
                allow_dangerous_deserialization=True,
            )
        elif db_type == "chroma":
            chroma_path = os.path.join(path, index_name)
            return Chroma(
                embedding_function=embeddings,
                persist_directory=chroma_path,
                collection_name="chroma_db",
            )
        else:
            raise ValueError(f"âŒ [Value] (vector_db.load_vector_db) ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²¡í„° DB íƒ€ì…ì…ë‹ˆë‹¤. {db_type}")

    except Exception as e:
        raise RuntimeError(f"âŒ [Runtime] (vector_db.load_vector_db) ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")


def add_docs_in_batch(
    vector_store: VectorStore,
    chunks: Optional[List[Document]],
    batch_size: int = 128
):
    """
    ë¬¸ì„œ chunkë¥¼ batchë³„ë¡œ ì¶”ê°€í•˜ëŠ” ë°©ì‹.
    """
    total = len(chunks)
    pbar = tqdm(
        range(0, total, batch_size),
        desc=f"    ğŸ“Œ Indexing chunks to {vector_store.__class__.__name__}",
        unit="batch",
    )

    for i in pbar:
        batch = chunks[i:i + batch_size]
        vector_store.add_documents(batch)

        end_idx = min(i + batch_size, total)
        pbar.set_postfix_str(f"Indexed {end_idx} / {total}")

    return vector_store
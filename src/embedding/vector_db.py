import os
from typing import List, Union, Optional, Literal

import faiss
from dotenv import load_dotenv
from tqdm import tqdm

from langsmith import trace
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_chroma import Chroma
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.vectorstores.base import VectorStore

from src.utils.path import get_project_root_dir


def generate_embedding(embed_model_name: str) -> Union[OpenAIEmbeddings, HuggingFaceEmbeddings]:
    """
    ì£¼ì–´ì§„ ëª¨ë¸ ì´ë¦„ì— ë”°ë¼ OpenAI ë˜ëŠ” HuggingFace ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        embed_model_name (str): ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„. 'openai' ë˜ëŠ” Hugging Face ëª¨ë¸ ì´ë¦„

    Returns:
        Union[OpenAIEmbeddings, HuggingFaceEmbeddings]: ì´ˆê¸°í™”ëœ ì„ë² ë”© ëª¨ë¸ ê°ì²´

    Raises:
        ValueError: API í‚¤ ëˆ„ë½ ë˜ëŠ” ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
    """
    try:
        if embed_model_name == "openai":
            load_dotenv()
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return OpenAIEmbeddings(model="text-embedding-3-large", openai_api_key=api_key)
        else:
            return HuggingFaceEmbeddings(model_name=embed_model_name)
    except Exception as e:
        raise ValueError(f"âŒ [Value] (vector_db.generate_embedding) ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


@trace(name="generate_vector_db")
def generate_vector_db(
    all_chunks: List[Document],
    embed_model_name: str,
    index_name: str,
    db_type: str = "faiss",
    is_save: bool = True,
    batch_size: int = 128
) -> Union[FAISS, Chroma]:
    """
    ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ìš©í•´ FAISS ë˜ëŠ” Chroma ê¸°ë°˜ì˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê³ ,
    ì§€ì •ëœ ê²½ë¡œì— ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    Args:
        all_chunks (List[Document]): ì„ë² ë”©í•  ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        embed_model_name (str): ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        index_name (str): ì €ì¥í•  ë²¡í„° DBì˜ ì¸ë±ìŠ¤ ì´ë¦„
        db_type (str): ì‚¬ìš©í•  ë²¡í„° ì €ì¥ì†Œ ìœ í˜• ('faiss' ë˜ëŠ” 'chroma')
        is_save (bool): DB ì €ì¥ ì—¬ë¶€ (faissë§Œ í•´ë‹¹)
        batch_size (int): ë¬¸ì„œ ì‚½ì… ì‹œ ë°°ì¹˜ í¬ê¸°

    Returns:
        Union[FAISS, Chroma]: ìƒì„±ëœ ë²¡í„° DB ì¸ìŠ¤í„´ìŠ¤

    Raises:
        ValueError: ì˜ëª»ëœ ì…ë ¥ ê°’ì´ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” DB íƒ€ì… ì…ë ¥ ì‹œ
        RuntimeError: ë²¡í„° DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
    """
    if not all_chunks or not isinstance(all_chunks, list):
        raise ValueError("âŒ [Value] (vector_db.generate_vector_db) all_chunksëŠ” ë¹„ì–´ ìˆì§€ ì•Šì€ Document ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    embeddings = generate_embedding(embed_model_name)
    print(f"ğŸ“Œ [Info] Embedding model: {embeddings.__class__.__name__}")

    try:
        if isinstance(embeddings, (HuggingFaceEmbeddings, OpenAIEmbeddings)):
            dimension = len(embeddings.embed_query("hello world"))
        else:
            dimension = 1536  # default
    except Exception as e:
        raise ValueError(f"âŒ [Value] (vector_db.generate_vector_db) ì„ë² ë”© ì°¨ì› ê³„ì‚° ì‹¤íŒ¨: {e}")

    try:
        output_path = os.path.join(get_project_root_dir(), "data")
        os.makedirs(output_path, exist_ok=True)

        if db_type == "faiss":
            print(f"ğŸ“Œ [info] Vector DB type: {db_type}")
            vector_store = FAISS(
                embedding_function=embeddings,
                index=faiss.IndexFlatL2(dimension),
                docstore=InMemoryDocstore(),
                index_to_docstore_id={},
            )
            vector_store = add_docs_in_batch(vector_store, all_chunks)
            if is_save:
                vector_store.save_local(folder_path=output_path, index_name=index_name)
                print("âœ… [Success] FAISS vector DB ì €ì¥ ì„±ê³µ.")

        elif db_type == "chroma":
            print(f"ğŸ“Œ [info] Vector DB type: {db_type}")
            chroma_path = os.path.join(output_path, index_name)
            if os.path.exists(chroma_path):
                import shutil
                shutil.rmtree(chroma_path)
                print(f"âš ï¸ [Notification] {db_type} ë®ì–´ì“°ê¸° ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ì´ì „ ìƒì„± DB ì œê±°...")

            vector_store = Chroma(
                embedding_function=embeddings,
                persist_directory=chroma_path,
                collection_name="chroma_db",
            )
            vector_store = add_docs_in_batch(vector_store, all_chunks)
            print("âœ… [Success] Chroma vector DB ì €ì¥ ì„±ê³µ.")

        else:
            raise ValueError("âŒ [Value] (vector_db.generate_vector_db) ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²¡í„° DB íƒ€ì…ì…ë‹ˆë‹¤. ('faiss' ë˜ëŠ” 'chroma' ì‚¬ìš©)")

        return vector_store

    except Exception as e:
        raise RuntimeError(f"âŒ [Runtime] (vector_db.generate_vector_db) ë²¡í„° DB ìƒì„± ì‹¤íŒ¨: {e}")


@trace(name="load_vector_db")
def load_vector_db(
    path: str,
    embed_model_name: str,
    index_name: str,
    db_type: str = "faiss"
) -> Union[FAISS, Chroma]:
    """
    ì €ì¥ëœ FAISS ë˜ëŠ” Chroma ë²¡í„° DBë¥¼ ë¡œì»¬ ê²½ë¡œì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        path (str): ì €ì¥ëœ ë²¡í„° DBì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        embed_model_name (str): ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        index_name (str): ë¶ˆëŸ¬ì˜¬ ë²¡í„° DBì˜ ì¸ë±ìŠ¤ ì´ë¦„
        db_type (str): ë²¡í„° DB ìœ í˜• ('faiss' ë˜ëŠ” 'chroma')

    Returns:
        Union[FAISS, Chroma]: ë¡œë“œëœ ë²¡í„° DB ì¸ìŠ¤í„´ìŠ¤

    Raises:
        FileNotFoundError: ì§€ì •í•œ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” DB íƒ€ì…ì¼ ê²½ìš°
        RuntimeError: ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ [FileNotFound] (vector_db.load_vector_db.path) ë²¡í„° DB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")

    try:
        embeddings = generate_embedding(embed_model_name)

        if db_type == "faiss":
            return FAISS.load_local(
                folder_path=path,
                index_name=index_name,
                embeddings=embeddings,
                allow_dangerous_deserialization=True,
            )
        elif db_type == "chroma":
            chroma_path = os.path.join(path, index_name)
            return Chroma(
                embedding_function=embeddings,
                persist_directory=chroma_path,
                collection_name="chroma_db",
            )
        else:
            raise ValueError(f"âŒ [Value] (vector_db.load_vector_db) ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²¡í„° DB íƒ€ì…ì…ë‹ˆë‹¤. {db_type}")

    except Exception as e:
        raise RuntimeError(f"âŒ [Runtime] (vector_db.load_vector_db) ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")


def add_docs_in_batch(
    vector_store: VectorStore,
    chunks: Optional[List[Document]],
    batch_size: int = 128
):
    """
    ì£¼ì–´ì§„ ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ë°°ì¹˜ í¬ê¸°(batch size)ë¡œ ë‚˜ëˆ„ì–´ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€í•©ë‹ˆë‹¤.

    Args:
        vector_store (VectorStore): ë¬¸ì„œê°€ ì‚½ì…ë  ë²¡í„° ì €ì¥ì†Œ ê°ì²´
        chunks (Optional[List[Document]]): ì‚½ì…í•  ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        batch_size (int): í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œì˜ ìˆ˜

    Returns:
        VectorStore: ë¬¸ì„œê°€ ì‚½ì…ëœ ë²¡í„° ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤
    """
    total = len(chunks)
    pbar = tqdm(
        range(0, total, batch_size),
        desc=f"    ğŸ“Œ Indexing chunks to {vector_store.__class__.__name__}",
        unit="batch",
    )

    for i in pbar:
        batch = chunks[i:i + batch_size]
        vector_store.add_documents(batch)

        end_idx = min(i + batch_size, total)
        pbar.set_postfix_str(f"Indexed {end_idx} / {total}")

    return vector_store
from typing import List, Optional, Union

from langsmith import traceable
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings

from src.retrieval.retrieval import retrieve_documents
from src.embedding.vector_db import load_vector_db
from src.embedding.embedding_main import generate_index_name

@traceable(name="retrieval_main")
def retrieval_main(
    config: dict,
    vector_store: Optional[object],
    chunks: List[Document],
    embeddings: Union[HuggingFaceEmbeddings, OpenAIEmbeddings],
    chat_history: Optional[str] = None
) -> List[Document]:
    """
    ì„¤ì •ì— ë”°ë¼ similarity ë˜ëŠ” hybrid ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , í•„ìš”ì‹œ re-rankingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        config (dict): ì„¤ì • ì •ë³´
        vector_store (VectorStore or None): ê¸°ì¡´ ë¡œë“œëœ ë²¡í„° ì €ì¥ì†Œ, ì—†ìœ¼ë©´ ë¡œë“œ
        chunks (List[Document]): hybrid ê²€ìƒ‰ ì‹œ ì‚¬ìš©í•  ì „ì²´ ë¬¸ì„œ ì²­í¬

    Returns:
        List[Document]: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ë‹´ì€ Document ë¦¬ìŠ¤íŠ¸
    """
    index_name = generate_index_name(config)

    vector_db_path = config["embedding"]["vector_db_path"]
    
    db_type = config["embedding"]["db_type"]

    if vector_store is None:
        vector_store = load_vector_db(
            path=vector_db_path,
            embeddings=embeddings,
            index_name=index_name,
            db_type=db_type,
        )

    docs = retrieve_documents(
        vector_store=vector_store,
        chunks=chunks,
        config=config,
        chat_history=chat_history
    )
    print("âœ… ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
    
    verbose = config["settings"]["verbose"]

    if verbose:
        count = 0
        for i, doc in enumerate(docs, 1):
            print(f"\n    ğŸ“„ ë¬¸ì„œ {i}")
            print(f"    - ë³¸ë¬¸(100ì): {doc.page_content[:100]}...")
            print(f"    - ë©”íƒ€ë°ì´í„°: {doc.metadata}")
            count += 1
            if count > 4:
                break

    return docs
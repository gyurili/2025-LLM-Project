from src.retrieval.retrieval import retrieve_documents
from src.embedding.vector_db import load_vector_db
from src.embedding.embedding_main import generate_index_name


def retrieval_main(config, vector_store, chunks):
    """
    ì„¤ì •ì— ë”°ë¼ similarity ë˜ëŠ” hybrid ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , í•„ìš”ì‹œ re-rankingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        config (dict): ì„¤ì • ì •ë³´
        vector_store (VectorStore or None): ê¸°ì¡´ ë¡œë“œëœ ë²¡í„° ì €ì¥ì†Œ, ì—†ìœ¼ë©´ ë¡œë“œ
        chunks (List[Document]): hybrid ê²€ìƒ‰ ì‹œ ì‚¬ìš©í•  ì „ì²´ ë¬¸ì„œ ì²­í¬

    Returns:
        List[Document]: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ë‹´ì€ Document ë¦¬ìŠ¤íŠ¸
    """
    index_name = generate_index_name(config)

    vector_db_path = config.get("embedding", {}).get("vector_db_path", "data")
    embed_model = config.get("embedding", {}).get("embed_model", "openai")
    db_type = config.get("embedding", {}).get("db_type", "faiss")

    if vector_store is None:
        vector_store=load_vector_db(vector_db_path, embed_model, index_name, db_type)
    
    query = config.get("retriever", {}).get("query", "")
    top_k = config.get("retriever", {}).get("top_k", 10)
    search_type = config.get("retriever", {}).get("search_type", "hybrid")
    rerank = config.get("retriever", {}).get("rerank", True)
    rerank_top_k = config.get("retriever", {}).get("rerank_top_k", 5)
    verbose = config.get("settings", {}).get("verbose", False)

    docs = retrieve_documents(query, vector_store, top_k, search_type, chunks, embed_model, rerank, rerank_top_k, verbose)
    
    if verbose:
        for i, doc in enumerate(docs, 1):
                print(f"\nğŸ“„ ë¬¸ì„œ {i}")
                print(f"ë³¸ë¬¸:\n{doc.page_content}...")
                print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
            
    return docs
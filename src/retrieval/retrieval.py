from typing import List, Optional, Literal
from collections import defaultdict, OrderedDict
from langchain.vectorstores.base import VectorStore
from langchain.schema import Document
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_openai import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from sklearn.metrics.pairwise import cosine_similarity
from src.embedding.vector_db import generate_embedding

import os
from dotenv import load_dotenv
load_dotenv()

def rerank_documents(
    query: str,
    docs: List[Document],
    embed_model,
    min_chunks: int,
    max_chunks: Optional[int] = None,
    verbose: bool = False
    ) -> List[Document]:
    """
        TODO:
        - ê²€ìƒ‰ëœ ë¬¸ì„œë§ˆë‹¤ ìµœì†Œ ì²­í¬ ìˆ˜ë¥¼ ë³´ìž¥í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

    ê²€ìƒ‰ì–´ì™€ ë¬¸ì„œ ê°„ ìž„ë² ë”© ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œë¥¼ ìž¬ì •ë ¬í•˜ì—¬ ìƒìœ„ Nê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìž ê²€ìƒ‰ ì¿¼ë¦¬
        docs (List[Document]): ê²€ìƒ‰ìœ¼ë¡œ ì¶”ì¶œëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        embed_model: ìž„ë² ë”© ëª¨ë¸ ê°ì²´
        min_chunks (int): ë¬¸ì„œë³„ ë³´ìž¥ë˜ëŠ” ìµœì†Œ ì²­í¬ ìˆ˜

    Returns:
        List[Document]: ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ìž¬ì •ë ¬ëœ ìƒìœ„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    if verbose:
        print("\nðŸ“Œ ê¸°ì¡´ ë¬¸ì„œ ìˆœì„œ:")
        for i, doc in enumerate(docs, 1):
            print(f"  {i}. íŒŒì¼ëª…: {doc.metadata.get('íŒŒì¼ëª…')}, ì²­í¬: {doc.metadata.get('chunk_idx')}")
    
    query_vec = embed_model.embed_query(query)
    doc_vecs = embed_model.embed_documents([doc.page_content for doc in docs])
    
    query_vec = [query_vec]
    similarities = cosine_similarity(query_vec, doc_vecs)[0]
    
    doc_scores = [(doc, score) for doc, score in zip(docs, similarities)]
    doc_scores.sort(key=lambda x: x[1], reverse=True)
    
    if verbose:
        print("\nðŸ“Œ re-rank ì ìš© í›„ ë¬¸ì„œ ìˆœì„œ:")
        for i, (doc, score) in enumerate(doc_scores, 1):
            print(f"  {i}. íŒŒì¼ëª…: {doc.metadata.get('íŒŒì¼ëª…')}, ì²­í¬: {doc.metadata.get('chunk_idx')}, ìœ ì‚¬ë„: {score:.4f}")
    
    grouped = OrderedDict()
    for doc, score in doc_scores:
        fname = doc.metadata.get("íŒŒì¼ëª…")
        if fname not in grouped:
            grouped[fname] = []
        grouped[fname].append((doc, score))

    selected_set = set()
    selected_docs = []

    for fname, group in grouped.items():
        limit = max_chunks if max_chunks else len(group)
        group_sorted = sorted(group, key=lambda x: x[1], reverse=True)

        count = 0
        for doc, _ in group_sorted:
            doc_id = (doc.metadata.get("íŒŒì¼ëª…"), doc.metadata.get("chunk_idx"))
            if doc_id not in selected_set:
                selected_docs.append(doc)
                selected_set.add(doc_id)
                count += 1
            if count >= max(min_chunks, limit):
                break

    if verbose:
        print("\nðŸ“Œ ìµœì¢… ì„ íƒëœ ë¬¸ì„œ:")
        for i, doc in enumerate(selected_docs, 1):
            print(f"  {i}. íŒŒì¼ëª…: {doc.metadata.get('íŒŒì¼ëª…')}, ì²­í¬: {doc.metadata.get('chunk_idx')}")

    return selected_docs


def retrieve_documents(
    query: str,
    vector_store: VectorStore,
    top_k: int,
    search_type: Literal["similarity", "hybrid"],
    chunks: Optional[List[Document]],
    embed_model_name: str,
    rerank: bool,
    min_chunks: int,
    verbose: bool = False
) -> List[Document]:
    """
        TODO:
        - ë¬¸ì„œ ê·¸ë£¨í•‘ ë° ëŒ€í‘œ ì ìˆ˜ ê³„ì‚°ì„ í†µí•´ ìœ ì‚¬í•œ ë¬¸ì„œ ê·¸ë£¹ì„ ì„ íƒí•˜ëŠ” ë¡œì§ì„ ê°œì„ í•©ë‹ˆë‹¤.

    ì£¼ì–´ì§„ ì¿¼ë¦¬ì— ëŒ€í•´ similarity ë˜ëŠ” hybrid ê²€ìƒ‰ ë°©ì‹ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query (str): ì‚¬ìš©ìž ê²€ìƒ‰ ì¿¼ë¦¬
        vector_store (VectorStore): ë²¡í„° ì €ìž¥ì†Œ ì¸ìŠ¤í„´ìŠ¤
        top_k (int): ê²€ìƒ‰í•  ìµœëŒ€ ë¬¸ì„œ ê°œìˆ˜
        search_type (Literal["similarity", "hybrid"]): ê²€ìƒ‰ ë°©ì‹
        chunks (Optional[List[Document]]): hybrid ê²€ìƒ‰ì„ ìœ„í•œ ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        embed_model_name (str): ì‚¬ìš©í•  ìž„ë² ë”© ëª¨ë¸ ì´ë¦„
        rerank (bool): re-ranking ì ìš© ì—¬ë¶€
        min_chunks (int): ë¬¸ì„œë§ˆë‹¤ ë³´ìž¥ë˜ëŠ” ìµœì†Œ ì²­í¬ ìˆ˜

    Returns:
        List[Document]: ê²€ìƒ‰ ë˜ëŠ” ìž¬ì •ë ¬ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

    Raises:
        RuntimeError: retriever ìƒì„±ì— ì‹¤íŒ¨í•  ê²½ìš°
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²€ìƒ‰ ë°©ì‹ ë˜ëŠ” chunks ë¯¸ì œê³µ ì‹œ
    """
    
    embed_model = generate_embedding(embed_model_name=embed_model_name)
    
    if search_type == "similarity":
        docs = vector_store.similarity_search(query, k=top_k * 5)
        
    elif search_type == "hybrid":
        if chunks is None:
            raise ValueError("âŒ [Value] (retrieval.retrieve_documents.chunks) hybrid ê²€ìƒ‰ì„ ìœ„í•´ chunksê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        try:
            vector_retriever = vector_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": top_k * 5}
            )
        except Exception as e:
            raise RuntimeError(f"âŒ [Runtime] (retrieval.retrieve_documents.vector_retriever) FAISS retriever ìƒì„± ì‹¤íŒ¨: {e}")
    
        try:
            bm25_retriever = BM25Retriever.from_documents(chunks)
            bm25_retriever.k = top_k * 5
        except Exception as e:
            raise RuntimeError(f"âŒ [Runtime] (retrieval.retrieve_documents.bm25_retriever) BM25 retriever ìƒì„± ì‹¤íŒ¨: {e}")
        
        hybrid_retriever = EnsembleRetriever(
            retrievers=[bm25_retriever, vector_retriever],
            weights=[0.5, 0.5]
        )
        docs = hybrid_retriever.invoke(query)
        
    else:
        raise ValueError(f"âŒ [Value] (retrieval.retrieve_documents.search_type) ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²€ìƒ‰ ë°©ì‹ìž…ë‹ˆë‹¤: {search_type}")
    
    # ë¬¸ì„œ ê·¸ë£¹í™” ë° ê° ë¬¸ì„œë‹¹ ìµœì†Œ ì²­í¬ ìˆ˜ ë³´ìž¥
    doc_groups = defaultdict(list)
    for doc in docs:
        fname = doc.metadata.get("íŒŒì¼ëª…")
        doc_groups[fname].append(doc)

    query_vec = embed_model.embed_query(query)
    selected_docs = []
    for fname, group in doc_groups.items():
        if len(group) > 1:
            doc_vecs = embed_model.embed_documents([doc.page_content for doc in group])
            similarities = cosine_similarity([query_vec], doc_vecs)[0]
            ranked_group = sorted(zip(group, similarities), key=lambda x: x[1], reverse=True)
            selected_docs.extend([doc for doc, _ in ranked_group])
        else:
            selected_docs.append(group[0])

    docs = selected_docs

    if rerank:
        docs = rerank_documents(query, docs, embed_model, min_chunks, max_chunks=5, verbose=verbose)

    return docs
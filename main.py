import os
import yaml

from src.data_loader import data_load, data_process, data_chunking
from src.vector_db import generate_vector_db, load_vector_db

# from src.retrieval import retrieve_documents


# if __name__ == "__main__":
#     try:
#         # Config ë¶ˆëŸ¬ì˜¤ê¸°
#         with open("config.yaml", "r", encoding="utf-8") as f:
#             config = yaml.safe_load(f)

#         # ì„¤ì • Config
#         settings_config = config.get("settings", {})
#         if not isinstance(settings_config, dict):
#             raise ValueError("âŒ(config.settings) ì„¤ì •ì€ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         # verbose ì„¤ì •
#         verbose = settings_config.get("verbose", False)
#         if not isinstance(verbose, bool):
#             raise ValueError("âŒ(config.settings.verbose) verboseëŠ” True ë˜ëŠ” Falseì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         # verbose ì¶œë ¥
#         if verbose:
#             print("    -Verbose ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")

#         # ë°ì´í„° Config
#         data_config = config.get("data", {})
#         if not isinstance(data_config, dict):
#             raise ValueError("âŒ(config.data) ë°ì´í„° ì„¤ì •ì€ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         # HWP íŒŒì¼ì„ PDFë¡œ ë³€í™˜
#         folder_path = os.path.abspath(data_config.get("folder_path", ""))
#         if not isinstance(folder_path, str):
#             raise ValueError("âŒ(config.data.folder_path) í´ë” ê²½ë¡œëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
#         if not os.path.exists(folder_path):
#             raise FileNotFoundError(f"âŒ(config.data.folder_path) í´ë” ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
#         # batch_convert_hwp_to_pdf(folder_path)

#         # ë°ì´í„° ë¡œë“œ
#         data_list_path = os.path.abspath(data_config.get("data_list_path", ""))
#         if not isinstance(data_list_path, str):
#             raise ValueError("âŒ(config.data.data_list_path) ë°ì´í„° ëª©ë¡ ê²½ë¡œëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
#         if not os.path.exists(data_list_path):
#             raise FileNotFoundError(f"âŒ(config.data.data_list_path) íŒŒì¼ ëª©ë¡ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_list_path}")
#         limit = data_config.get("limit", 5)
#         if not isinstance(limit, int):
#             raise ValueError("âŒ(config.data.limit) limitì€ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
#         # verbose ì¶œë ¥
#         if verbose:
#             print(f"    -í´ë” ê²½ë¡œ: {folder_path}")
#             print(f"    -ë°ì´í„° ë¡œë“œ ê²½ë¡œ: {data_list_path}")
#             print(f"    -íŒŒì¼ ìˆ˜ ì œí•œ: {limit}")

#         df = data_load(data_list_path, limit=limit)
#         print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

#         # ë°ì´í„° ì „ì²˜ë¦¬
#         file_type = data_config.get("file_type", "all")
#         if file_type not in ["hwp", "pdf", "all"]:
#             raise ValueError("âŒ(config.data.type) file_typeì€ 'hwp', 'pdf', 'all' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         apply_ocr = data_config.get("apply_ocr", False)
#         if not isinstance(apply_ocr, bool):
#             raise ValueError("âŒ(config.data.apply_ocr) apply_ocrëŠ” True ë˜ëŠ” Falseì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
#         # verbose ì¶œë ¥
#         if verbose:
#             print(f"    -íŒŒì¼ íƒ€ì…: {file_type}")
#             print(f"    -OCR ì ìš© ì—¬ë¶€: {apply_ocr}")

#         df = data_process(df, apply_ocr=apply_ocr, file_type=file_type)
#         print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")

#         # ì²­í¬ Config
#         chunk_config = config.get("chunk", {})
#         if not isinstance(chunk_config, dict):
#             raise ValueError("âŒ(config.chunk) ì²­í¬ ì„¤ì •ì€ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
#         # ì²­í¬ ë¶„í• ê¸° ì„¤ì •
#         splitter_type = chunk_config.get("splitter", "")
#         if not isinstance(splitter_type, str) or not splitter_type:
#             raise ValueError("âŒ(config.chunk.splitter) ì²­í¬ ë¶„í• ê¸° íƒ€ì…ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
#         chunk_size = chunk_config.get("size", 300)
#         if chunk_size <= 0 or not isinstance(chunk_size, int):
#             raise ValueError("âŒ(config.chunk.size) ì²­í¬ í¬ê¸°ëŠ” 1 ì´ìƒì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         chunk_overlap = chunk_config.get("overlap", 50)
#         if chunk_overlap < 0 or not isinstance(chunk_overlap, int):
#             raise ValueError("âŒ(config.chunk.overlap) ì²­í¬ ì˜¤ë²„ë©ì€ 0 ì´ìƒì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         if verbose:
#             print(f"    -ì²­í¬ ë¶„í• ê¸° íƒ€ì…: {splitter_type}")
#             print(f"    -ì²­í¬ í¬ê¸°: {chunk_size}")
#             print(f"    -ì²­í¬ ì˜¤ë²„ë©: {chunk_overlap}")

#         all_chunks = data_chunking(df=df, splitter_type=splitter_type, size=chunk_size, overlap=chunk_overlap)
#         print("âœ… ì²­í¬ ìƒì„± ì™„ë£Œ")        

#         # ë²¡í„° DB Config
#         embed_config = config.get("embedding", {})
#         if not isinstance(embed_config, dict):
#             raise ValueError("âŒ(config.embedding) ë²¡í„° DB ì„¤ì •ì€ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         index_name = generate_index_name(config)
        
#         # ë²¡í„° DB ìƒì„± ë˜ëŠ” ë¡œë“œ
#         embed_model = embed_config.get("model", "openai")
#         if not isinstance(embed_model, str) or not embed_model:
#             raise ValueError("âŒ(config.embedding.model) ì„ë² ë”© ëª¨ë¸ëª…ì´ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
#         vector_db_path = embed_config.get("vector_db_path", "")
#         if not isinstance(vector_db_path, str):
#             raise ValueError("âŒ(config.embedding.vector_db_path) ë²¡í„° DB ê²½ë¡œëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
#         if not os.path.exists(vector_db_path):
#             os.makedirs(vector_db_path, exist_ok=True)
#         db_type = embed_config.get("db_type", "faiss")
#         if db_type == "faiss":
#             faiss_file = os.path.join(vector_db_path, f"{index_name}.faiss")
#             pkl_file = os.path.join(vector_db_path, f"{index_name}.pkl")
#             db_exists = os.path.exists(faiss_file) and os.path.exists(pkl_file)
#         elif db_type == "chroma":
#             chroma_dir = os.path.join(vector_db_path, index_name)
#             db_exists = os.path.isdir(chroma_dir) and os.path.exists(os.path.join(chroma_dir, "chroma.sqlite3"))
#         else:
#             raise ValueError(f"âŒ(config.embedding.db_type) ì§€ì›í•˜ì§€ ì•ŠëŠ” DB íƒ€ì…ì…ë‹ˆë‹¤: {db_type}")

#         # verbose ì¶œë ¥
#         if verbose:
#             print(f"    -ì„ë² ë”© ëª¨ë¸: {embed_model}")
#             print(f"    -DB íƒ€ì…: {db_type}")
#             print(f"    -ë²¡í„° DB ê²½ë¡œ: {vector_db_path}")
#             print(f"    -ë²¡í„° DB íŒŒì¼: {index_name}")

#         if db_exists:
#             # ë²¡í„° DBê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°
#             if verbose:
#                 print(f"âœ… ê¸°ì¡´ ë²¡í„° DB ê²½ë¡œ ë°œê²¬ë¨: {index_name} ë¡œë“œí•©ë‹ˆë‹¤.")
#             vector_store = load_vector_db(vector_db_path, embed_model, index_name, db_type)
#             print("âœ… Vector DB ë¡œë“œ ì™„ë£Œ")
#         else:
#             # ë²¡í„° DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
#             if verbose:
#                 print(f"âœ… ë²¡í„° DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„± í›„ ì €ì¥í•©ë‹ˆë‹¤: {vector_db_path}")
#             vector_store = generate_vector_db(all_chunks, embed_model, index_name, db_type)
#             print("âœ… Vector DB ìƒì„± ì™„ë£Œ")

#         # ì¿¼ë¦¬ Config
#         query_config = config.get("query", {})
#         if not isinstance(query_config, dict):
#             raise ValueError("âŒ(config.query) ì¿¼ë¦¬ ì„¤ì •ì€ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
#         # ìœ ì‚¬ë„ ê²€ìƒ‰
#         query = query_config.get("question", "")
#         if not isinstance(query, str):
#             raise ValueError("âŒ(config.query.question) queryëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
#         top_k = query_config.get("top_k", 5)
#         if not isinstance(top_k, int) or top_k <= 0:
#             raise ValueError("âŒ(config.query.top_k) top_këŠ” 1 ì´ìƒì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
#         if verbose:
#             print(f"    -ìœ ì‚¬ë„ ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
#             print(f"    -ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜: {top_k}")
        
#         search_type = config.get("retrieval", {}).get("search_type", "similarity")
#         if not isinstance(search_type, str):
#             raise ValueError("âŒ(config.retrieval.method) ê²€ìƒ‰ ë°©ì‹ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
#         docs = retrieve_documents(query, vector_store, top_k, search_type, all_chunks)
#         for i, doc in enumerate(docs, 1):
#             print(f"\nğŸ“„ ë¬¸ì„œ {i}")
#             print(f"ë³¸ë¬¸:\n{doc['text'][:300]}...")
#             print(f"ë©”íƒ€ë°ì´í„°: {doc['metadata']}")


#     # ì˜ˆì™¸ ì²˜ë¦¬
#     except FileNotFoundError as e:
#         print(f"âŒ [FileNotFound] \n  {e}")

#     except ValueError as e:
#         print(f"âŒ [Value] \n  {e}")

#     except TypeError as e:
#         print(f"âŒ [Type] \n  {e}")

#     except yaml.YAMLError as e:
#         print(f"âŒ [YAML] config.yaml íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: \n  {e}")

#     except ImportError as e:
#         print(f"âŒ [Import] ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: \n  {e}")

#     except Exception as e:
#         print(f"âŒ [Runtime] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: \n  {e}")
import os
import shutil
import streamlit as st

from src.utils.path import get_project_root_dir
from src.utils.config import load_config
from src.loader.loader_main import loader_main
from src.embedding.embedding_main import embedding_main
from src.retrieval.retrieval_main import retrieval_main
from src.generator.generator_main import generator_main
from src.embedding.embedding_main import generate_index_name

project_root = get_project_root_dir()
config_path = os.path.join(project_root, "config.yaml")
config = load_config(config_path)

st.set_page_config(page_title="RAG Demo", layout="wide")
st.title("ğŸ§  ì§ˆë¬¸ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ê´€ë ¨ ë¬¸ì„œ ì¶”ì¶œ (Retriever Only)")

# ======================
# ğŸ”§ ì„¤ì • ì˜µì…˜ UI
# ======================

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ë°ì´í„° ê´€ë ¨
    st.subheader("ğŸ“‚ ë°ì´í„° ì„¤ì •")
    config["data"]["top_k"] = st.slider("ğŸ”¢ ìµœëŒ€ ë¬¸ì„œ ìˆ˜(top_k)", 1, 100, config["data"]["top_k"])
    config["data"]["file_type"] = st.selectbox("ğŸ“„ íŒŒì¼ ìœ í˜•", ["all", "pdf", "hwp"], index=["all", "pdf", "hwp"].index(config["data"]["file_type"]))
    config["data"]["apply_ocr"] = st.toggle("ğŸ§¾ OCR ì ìš© ì—¬ë¶€", config["data"]["apply_ocr"])
    config["data"]["splitter"] = st.selectbox("âœ‚ï¸ ë¬¸ì„œ ë¶„í•  ë°©ë²•", ["recursive", "token"], index=["recursive", "token"].index(config["data"]["splitter"]))
    config["data"]["chunk_size"] = st.number_input("ğŸ“ Chunk í¬ê¸°", value=config["data"]["chunk_size"], step=100)
    config["data"]["chunk_overlap"] = st.number_input("ğŸ” Chunk ì˜¤ë²„ë©", value=config["data"]["chunk_overlap"], step=10)

    # ì„ë² ë”© ì„¤ì •
    st.subheader("ğŸ§  ì„ë² ë”© ì„¤ì •")
    config["embedding"]["embed_model"] = st.text_input("ğŸ§¬ ì„ë² ë”© ëª¨ë¸", config["embedding"]["embed_model"])
    config["embedding"]["db_type"] = st.selectbox("ğŸ’¾ Vector DB íƒ€ì…", ["faiss", "chroma"], index=["faiss", "chroma"].index(config["embedding"]["db_type"]))

    if config["embedding"]["embed_model"].strip().lower() == "openai":
        openai_key = st.text_input("ğŸ”‘ OpenAI API Key", type="password")
        os.environ["OPENAI_API_KEY"] = openai_key  # í•„ìš”í•œ ê²½ìš° í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
        if not openai_key:
            st.warning("OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")

    # ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
    st.subheader("ğŸ” ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •")
    config["retriever"]["search_type"] = st.selectbox("ğŸ” ê²€ìƒ‰ ë°©ì‹", ["similarity", "hybrid"], index=["similarity", "hybrid"].index(config["retriever"]["search_type"]))
    config["retriever"]["top_k"] = st.slider("ğŸ“„ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", 1, 20, config["retriever"]["top_k"])
    config["retriever"]["rerank"] = st.toggle("ğŸ“Š ë¦¬ë­í¬ ì ìš©", config["retriever"]["rerank"])
    config["retriever"]["rerank_top_k"] = st.slider("ğŸ” ë¦¬ë­í¬ ë¬¸ì„œ ìˆ˜", 1, 20, config["retriever"]["rerank_top_k"])

    reset_vector_db = st.button("âš ï¸ Vector DB ì´ˆê¸°í™”")
    
    if config["embedding"]["db_type"] == "faiss":
        faiss_index_name = f"{generate_index_name(config)}"
        vector_db_file = os.path.join(project_root, 'data', f"{faiss_index_name}.faiss")
        metadata_file = os.path.join(project_root, 'data', f"{faiss_index_name}.pkl")
    else:
        chroma_folder_name = f"{generate_index_name(config)}"
        chroma_path = os.path.join(project_root, 'data', chroma_folder_name)


    if reset_vector_db:
        # ì„ íƒëœ ë²¡í„° DB ê²½ë¡œ ì‚­ì œ
        if config["embedding"]["db_type"] == "faiss":
            if os.path.exists(vector_db_file):
                os.remove(vector_db_file)
                os.remove(metadata_file)
                st.success("FAISS DB ì‚­ì œ ì™„ë£Œ")
        elif config["embedding"]["db_type"] == "chroma":
            import shutil
            if os.path.exists(chroma_path):
                shutil.rmtree(chroma_path)
                st.success("Chroma DB ì‚­ì œ ì™„ë£Œ")
        else:
            st.info("ì‚­ì œí•  íŒŒì¼ ë° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")


def run_rag_pipeline(config):
    if config["data"]["top_k"] == 100:
        if config["embedding"]["db_type"] == "faiss":
            is_save = not os.path.exists(vector_db_file)
        elif config["embedding"]["db_type"] == "chroma":
            is_save = not os.path.exists(chroma_path)
        else:
            is_save = True
    else:
        is_save = True

    chunks = loader_main(config) if is_save else []

    with st.spinner("ğŸ“‚ ê´€ë ¨ ë¬¸ì„œ ì„ë² ë”© ì¤‘..."):
        vector_store = embedding_main(config, chunks, is_save=is_save)

    with st.spinner("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
        docs = retrieval_main(config, vector_store, chunks)

    st.markdown("### ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´")
    if isinstance(docs, list):
        if len(docs) > 1:
            for i, doc in enumerate(docs):
                with st.expander(f"[{i+1}] {doc.metadata.get('ì‚¬ì—…ëª…', 'ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ')}"):
                    st.write("ğŸ“„ **ë©”íƒ€ë°ì´í„°**")
                    st.json(doc.metadata)
                    st.write("ğŸ“ **ë¬¸ì„œ chunk ë‚´ìš©**")
                    st.write(doc.page_content)
        elif len(docs) == 1:
            doc = docs[0]
            st.write("ğŸ“„ **ë©”íƒ€ë°ì´í„°**")
            st.json(doc.metadata)
            st.info(doc.page_content)
        else:
            st.warning("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info(docs.page_content)

# ======================
# ğŸ¤– ì§ˆë¬¸ ì…ë ¥ ë° ì‹¤í–‰
# ======================
if "input_key_version" not in st.session_state:
    st.session_state.input_key_version = 0

def reset_query():
    st.session_state.input_key_version += 1
    st.session_state.user_query = ""  # ìƒˆë¡œìš´ keyì—ì„  ë¬¸ì œ ì—†ìŒ
    st.session_state.trigger_search = False

# í•­ìƒ ì§ˆë¬¸ ì…ë ¥ì°½ ë³´ì—¬ì¤Œ
query_key = f"user_query_{st.session_state.input_key_version}"
query = st.text_input("â“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key=query_key)

if st.button("ğŸ” ê²€ìƒ‰") and query.strip():
    st.session_state.trigger_search = True
    st.session_state.user_query = query

if st.session_state.trigger_search:
    config["retriever"]["query"] = st.session_state.user_query
    st.markdown(f"### ğŸ™‹ ì…ë ¥í•œ ì§ˆë¬¸: `{st.session_state.user_query}`")

    # RAG ì‹¤í–‰
    run_rag_pipeline(config)

    reset_query()